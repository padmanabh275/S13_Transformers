{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c17de200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cpu\n",
      "Downloading and preparing dataset opus_books/en-it to C:/Users/pbosamia/.cache/huggingface/datasets/opus_books/en-it/1.0.0/e8f950a4f32dc39b7f9088908216cd2d7e21ac35f893d04d39eb594746af2daf...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350f3189060c45f592fed63328b9d8cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/32332 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset opus_books downloaded and prepared to C:/Users/pbosamia/.cache/huggingface/datasets/opus_books/en-it/1.0.0/e8f950a4f32dc39b7f9088908216cd2d7e21ac35f893d04d39eb594746af2daf. Subsequent calls will reuse this data.\n",
      "Max length of source sentence: 309\n",
      "Max length of target sentence: 309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 00:   0%|          | 0/4850 [00:00<?, ?it/s]\n",
      "Processing Epoch 01:   0%|          | 0/4850 [00:00<?, ?it/s]\n",
      "Processing Epoch 02:   0%|          | 0/4850 [00:00<?, ?it/s]\n",
      "Processing Epoch 03:   0%|          | 0/4850 [00:00<?, ?it/s]\n",
      "Processing Epoch 04:   0%|          | 0/4850 [00:00<?, ?it/s]\n",
      "Processing Epoch 05:   0%|          | 0/4850 [00:00<?, ?it/s]\n",
      "Processing Epoch 06:   0%|          | 0/4850 [00:00<?, ?it/s]\n",
      "Processing Epoch 07:   0%|          | 0/4850 [00:00<?, ?it/s]\n",
      "Processing Epoch 08:   0%|          | 0/4850 [00:00<?, ?it/s]\n",
      "Processing Epoch 09:   0%|          | 0/4850 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Sentence is too long",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m cfg[\u001b[39m'\u001b[39m\u001b[39mnum_epochs\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrain\u001b[39;00m \u001b[39mimport\u001b[39;00m train_model\n\u001b[1;32m----> 9\u001b[0m train_model(cfg)\n",
      "File \u001b[1;32mc:\\Users\\pbosamia\\OneDrive - Deloitte (O365D)\\Documents\\School_of_AI\\S14_Transformers\\Uploads\\train.py:214\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m    211\u001b[0m     model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m    212\u001b[0m     batch_iterator\u001b[39m=\u001b[39mtqdm(train_dataloader,desc\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProcessing Epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m:\u001b[39;00m\u001b[39m02d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 214\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m batch_iterator:\n\u001b[0;32m    216\u001b[0m     encoder_input \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39mencoder_input\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device) \u001b[39m#(b,seq_len)\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     decoder_input \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39mdecoder_input\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device) \u001b[39m#(B,seq_len)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pbosamia\\Anaconda3\\lib\\site-packages\\tqdm\\std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pbosamia\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\pbosamia\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\pbosamia\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\pbosamia\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\pbosamia\\OneDrive - Deloitte (O365D)\\Documents\\School_of_AI\\S14_Transformers\\Uploads\\dataset.py:40\u001b[0m, in \u001b[0;36mBilingualDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39m# Make suer that the number of padding tokens is not negative. If it is, the sentence it too long\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[39mif\u001b[39;00m enc_num_padding_tokens \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m dec_num_padding_tokens \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 40\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mSentence is too long\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[39m# Add <s> and </s> token\u001b[39;00m\n\u001b[0;32m     43\u001b[0m encoder_input \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msos_token,\n\u001b[0;32m     44\u001b[0m                             torch\u001b[39m.\u001b[39mtensor(enc_input_tokens, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint64),\n\u001b[0;32m     45\u001b[0m                             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meos_token,\n\u001b[0;32m     46\u001b[0m                             torch\u001b[39m.\u001b[39mtensor([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpad_token] \u001b[39m*\u001b[39m enc_num_padding_tokens, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint64),\n\u001b[0;32m     47\u001b[0m                         ], dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Sentence is too long"
     ]
    }
   ],
   "source": [
    "from config import get_config\n",
    "cfg = get_config()\n",
    "cfg['batch_size'] = 6\n",
    "cfg['preload'] = None\n",
    "cfg['num_epochs'] = 10\n",
    "\n",
    "from train import train_model\n",
    "\n",
    "train_model(cfg)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
